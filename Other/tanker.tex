\section{Tanker}
Skaffe en divers gruppe samtykkende mennesker med flere former for bekledning; luer, caps, jakke, tskjorte. Eller bare meg, med masse ulike klær.

Image segmentation, hente ut utsnittet av menneskene;

Plassere disse menneskene på tilfeldige steder rundt i et område;

Trene datasettet på disse utsnittene;

Gjør vi det da bedre for det gitte området?


Kan dette streamlines, prosedurebeskrivelse:

1. Sett opp enheten fysisk der den skal sitte. 

2. Et bilde der det er ingen mennesker tas, og bruker verifiserer bildeområdet. Dette bildet beholdes og brukes senere i prosessen.

2. Bruker trykker på knapp: "start datainnsamling".

3. 10min: bruker/brukere beveger seg rundt, ulike posisjoner, ulike bekledning.

4. Datainnsamling fullført, enheten forsøker å hente ut menneskene i disse bildene, bruker korrigerer. Her vil det være nødvendig med et verktøy for bounding box der brukeren kan korrigere for hvert bilde som er blitt tatt.

5. Når utsnittene er korrekt satt, lagres de lokalt, og brukeren ferdig.

6. Enheten dupliserer det tomme bildet 100 000 ganger, og setter inn tilfeldige utsnitt på tilfeldige plasser i bildene. 

7. ML modell (vision transformer?) trenes på generelt dataset, så fyller på med disse bildene.


Highlights:

1. The produced dataset will be highly specialized to a specific area, thus possibly greatly increasing the accuracy for difficult scenarios.

2. The dataset will not be optimized to different situations, but the segmented people may possibly be applicable to insertion in similar environments (with respect to light conditions). 

3. Must be same light conditions in the whole operational period of the ML model.

4. Experiment to see if the produced data alone can suffice for similar accuracies on smaller models without the need of massive training, thus shifting the workload of machine learning to specialized data acquizition rather than computational heavy model training.


Questions:
Do the cameras need to be RGB? Why need colors? More information for the space if we see greygscale? Better accuracy with colors?

Use Raspberry Pi Black camera?
https://medium.com/@joehoeller/object-detection-on-thermal-images-f9526237686a

Må tilpasse yolov9 til antall klasser?


Hypothesises regarding museums:
Hvad er det der museumet er interessert i at finde ud?
    - Hvor lenge en person ser på hver fisk




Baseline creation:
1. Have the device function as normal, try to detect people. 
2. Improve it so it has detection algorithm more optimized for short distance detection
3. If not well: specialized dataset. If well: heatmap and efficiency.

Specialized dataset:
1. Setup camera and make it send images to a google bucket. 
2. Object detect persons on device, then send count and image to bucket.
3. Create code to obscure image before sending


Notes are taken on Work-Confluence as well for easier access and transparency with coworkers. 



TODO definisjoner/introduksjoner til begrep og teknologier som brukes i oppgaven:
IoT
Edge computing
    On-device processing
    Privacy-preserving
Computer vision
Object detection
    Artificial neural network
    Yolov9
    Pre-trained model
    Dataset
    Labeling
Raspberry Pi
    Picamera
Visitor analytics
    Fiskeri og Søfartsmuseet


Spørsmål til veileder:
Burde jeg ha med matematisk/dyp forklaring av hvordan picamera fungerer?
Er det viktig å inkorporere noe om hvordan en kunstig nevral nettverk fungerer, eller holder det med en kort forklaring av at det er en algoritme som lærer fra treningsdata for å kunne utføre en spesifikk oppgave?
