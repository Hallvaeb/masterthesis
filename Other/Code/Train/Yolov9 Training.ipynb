{"cells":[{"cell_type":"markdown","metadata":{"id":"heP9BncePJe3"},"source":["Attempted to push results to github but it resulted in filesize being too big (>100MB). Therefore, will try to save to drive instead, as downloading the file is ineffective. Github Credential Helper is likely redundant.\n","\n","Idea: zip everything but the weights, as they are the only thing really using storage. The rest can quickly be downloaded and evaluated, independently. Weights also need to be obtained, so drive is still wanted."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6PFozf_nFLbX","executionInfo":{"status":"ok","timestamp":1717071163006,"user_tz":-120,"elapsed":5,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}}},"outputs":[],"source":["import os\n","HOME = '/content'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23122,"status":"ok","timestamp":1717071187083,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"},"user_tz":-120},"id":"q6QO78R-MO75","outputId":"1be98e3b-cdd6-4d0b-af70-dff40178d0aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","DRIVE = HOME+'/drive'\n","drive.mount(DRIVE)\n","DRIVE = DRIVE+'/MyDrive'"]},{"cell_type":"code","source":["drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1ZlCrs4oGWk","executionInfo":{"status":"ok","timestamp":1717071192889,"user_tz":-120,"elapsed":5809,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"e0d00d6e-cec0-42c9-e8a8-0e5f811500de"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1717071192890,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"},"user_tz":-120},"id":"OKTxXR9TEtwn","outputId":"7c9a85ac-2cc4-414e-c5cc-e9c9822e242e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May 30 12:13:11 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"_x3HM5F0QUnp"},"source":["## Install yolov9 and pretrained weights"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717071192890,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"},"user_tz":-120},"id":"rzXx_a3-A0qn","outputId":"032b79b0-2ed4-42b9-aa78-75b0bedf4a44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov9-masterthesis'...\n","remote: Enumerating objects: 163, done.\u001b[K\n","remote: Counting objects: 100% (163/163), done.\u001b[K\n","remote: Compressing objects: 100% (117/117), done.\u001b[K\n","remote: Total 163 (delta 50), reused 148 (delta 39), pack-reused 0\u001b[K\n","Receiving objects: 100% (163/163), 581.46 KiB | 15.30 MiB/s, done.\n","Resolving deltas: 100% (50/50), done.\n"]}],"source":["!git clone https://github.com/Hallvaeb/yolov9-masterthesis.git"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60111,"status":"ok","timestamp":1717071252997,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"},"user_tz":-120},"id":"rvBXH0rXCt3D","outputId":"580a99e3-c6d8-4a32-a01d-cff4010b9cd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov9-masterthesis\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["%cd yolov9-masterthesis\n","!pip install -r requirements.txt -q"]},{"cell_type":"markdown","metadata":{"id":"3q2rjC3DFg1W"},"source":["## Download and prepare the dataset for training"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"F5opBxZWuYPj","executionInfo":{"status":"ok","timestamp":1717071257487,"user_tz":-120,"elapsed":5,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}}},"outputs":[],"source":["!mkdir -p {HOME}/dataset"]},{"cell_type":"code","source":["!unzip -n -q {DRIVE}/datasets/football-players-yolo.zip -d {HOME}/dataset"],"metadata":{"id":"b2oPpyWgJdfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","\n","labels_path = '/content/dataset/football-players-yolo/labels'\n","output_path = '/content/dataset/football-players-yolo'\n","\n","# Ratios for splitting the datasets\n","train_ratio = 1\n","val_ratio = 0\n","\n","# test_ratio is implicitly determined\n","\n","# Get all file names without their extensions\n","filenames = [os.path.splitext(file)[0] for file in os.listdir(labels_path) if os.path.isfile(os.path.join(labels_path, file))]\n","\n","# Shuffle the list of filenames to ensure random distribution\n","random.shuffle(filenames)\n","\n","# Calculate split indices\n","no_total_files = len(filenames)\n","train_end = int(no_total_files * train_ratio)\n","print(train_end)\n","print(no_total_files)\n","\n","if(no_total_files == train_end):\n","  train_end-=1\n","\n","val_end = train_end + int(no_total_files * val_ratio) +1\n","\n","# Split the filenames\n","train_filenames = filenames[:train_end]\n","val_filenames = filenames[train_end:val_end]\n","test_filenames = filenames[val_end:]\n","print(val_filenames)\n","\n","# Function to write filenames to a file\n","def write_filenames_to_file(filenames, file_path):\n","    with open(file_path, 'w') as file:\n","        for name in filenames:\n","            file.write(f'./images/{name}.jpg\\n')\n","\n","# Write the splits to their respective files\n","write_filenames_to_file(train_filenames, os.path.join(output_path, 'train.txt'))\n","write_filenames_to_file(val_filenames, os.path.join(output_path, 'val.txt'))\n","write_filenames_to_file(test_filenames, os.path.join(output_path, 'test.txt'))\n","\n","print(\"Files have been split and saved successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XO1i061AKEaS","executionInfo":{"status":"ok","timestamp":1716963219632,"user_tz":-120,"elapsed":308,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"d01da2e1-febb-45e2-e901-906cff5752db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["663\n","663\n","['538438_1_10_png.rf.394f8e55b797bda34d8c5600bc236474']\n","Files have been split and saved successfully.\n"]}]},{"cell_type":"markdown","source":["Now ensure yolov9-masterthesis/data.yaml is pointing to the right train and val txt files."],"metadata":{"id":"W3J5OhKQMCNz"}},{"cell_type":"markdown","metadata":{"id":"BkU6E-OfHfjl"},"source":["## Train the model\n","Prior to running this, /models/detect/yolov9-e.yaml was modified to have nc: 1. This file is responsible for the detector architecture. We freeze the backbone, to shorten training time."]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch -1 \\\n","--epochs 5 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/dataset/football-players-yolo/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project . \\\n","--single-cls \\\n","--noval \\\n","--weights /content/weights/yolov9-e.pt \\\n","--freeze 28\n","\n","# --device cpu \\\n","# --close-mosaic 15 \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOWS9PAzJrGF","executionInfo":{"status":"ok","timestamp":1716963810707,"user_tz":-120,"elapsed":343506,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"435172ea-e96f-4636-8db5-552775a13465"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-29 06:17:54.891639: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-29 06:17:54.891687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-29 06:17:54.893105: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-29 06:17:54.900365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-29 06:17:56.089820: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/weights/yolov9-e.pt, cfg=yolov9-e.yaml, data=/content/dataset/football-players-yolo/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=5, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=., name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir .', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 15.1MB/s]\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2160/2172 items from /content/weights/yolov9-e.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.75G total, 0.54G reserved, 0.53G allocated, 13.68G free\n","      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n","    69407846       244.8         1.718         126.5           nan        (1, 3, 640, 640)                    list\n","    69407846       489.7         2.674           104           nan        (2, 3, 640, 640)                    list\n","    69407846       979.4         4.977         150.9           nan        (4, 3, 640, 640)                    list\n","    69407846        1959         8.680         299.3           nan        (8, 3, 640, 640)                    list\n","CUDA out of memory. Tried to allocate 50.00 MiB. GPU \n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 10 for CUDA:0 11.82G/14.75G (80%) âœ…\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/football-players-yolo/train... 662 images, 0 backgrounds, 0 corrupt: 100% 662/662 [00:00<00:00, 5157.72it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/football-players-yolo/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/football-players-yolo/val... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<00:00, 123.92it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/football-players-yolo/val.cache\n","Plotting labels to exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mexp\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        0/4      9.67G      2.045      5.378      1.219        456        640:   0% 0/67 [00:02<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","        0/4      9.87G      1.648      1.822      1.089         52        640: 100% 67/67 [01:06<00:00,  1.00it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/4      9.87G      1.745          1      1.064         95        640: 100% 67/67 [00:54<00:00,  1.23it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/4      9.87G      1.774       1.04      1.057         77        640: 100% 67/67 [00:53<00:00,  1.25it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/4      9.87G      1.757     0.8453      1.053         81        640: 100% 67/67 [00:53<00:00,  1.25it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        4/4      9.87G       1.68     0.7765      1.048         91        640: 100% 67/67 [00:53<00:00,  1.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.55s/it]\n","                   all          1         22      0.997      0.955      0.986      0.679\n","\n","5 epochs completed in 0.084 hours.\n","Optimizer stripped from exp/weights/last.pt, 139.9MB\n","Optimizer stripped from exp/weights/best.pt, 139.9MB\n","\n","Validating exp/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.03it/s]\n","                   all          1         22      0.997      0.955      0.986      0.671\n","Results saved to \u001b[1mexp\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"exp\"\n","!zip -r {DRIVE}/football-5e.zip {HOME}/$results_saved_to"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IDxQiQUOMZ4j","executionInfo":{"status":"ok","timestamp":1716963826710,"user_tz":-120,"elapsed":15342,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"ad63d07c-7a95-4c71-a43b-8e2369f9076f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/exp/ (stored 0%)\n","  adding: content/exp/train_batch0.jpg (deflated 7%)\n","  adding: content/exp/F1_curve.png (deflated 16%)\n","  adding: content/exp/labels.jpg (deflated 29%)\n","  adding: content/exp/weights/ (stored 0%)\n","  adding: content/exp/weights/last.pt (deflated 8%)\n","  adding: content/exp/weights/best.pt (deflated 8%)\n","  adding: content/exp/R_curve.png (deflated 17%)\n","  adding: content/exp/events.out.tfevents.1716963477.faccc4e149c6.2768.0 (deflated 19%)\n","  adding: content/exp/confusion_matrix.png (deflated 41%)\n","  adding: content/exp/labels_correlogram.jpg (deflated 30%)\n","  adding: content/exp/P_curve.png (deflated 23%)\n","  adding: content/exp/PR_curve.png (deflated 29%)\n","  adding: content/exp/hyp.yaml (deflated 43%)\n","  adding: content/exp/train_batch1.jpg (deflated 16%)\n","  adding: content/exp/train_batch2.jpg (deflated 11%)\n","  adding: content/exp/results.csv (deflated 84%)\n","  adding: content/exp/val_batch0_labels.jpg (deflated 7%)\n","  adding: content/exp/val_batch0_pred.jpg (deflated 7%)\n","  adding: content/exp/opt.yaml (deflated 49%)\n","  adding: content/exp/results.png (deflated 13%)\n"]}]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 5 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/dataset/football-players-yolo/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project . \\\n","--single-cls \\\n","--noval \\\n","--weights /content/exp/weights/best.pt \\\n","--freeze 28\n","\n","# --weights /content/weights/yolov9-e.pt \\\n","# --device cpu \\\n","# --close-mosaic 15 \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-0a3g6aQ7AP","executionInfo":{"status":"ok","timestamp":1716964336839,"user_tz":-120,"elapsed":329806,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"50d5cca7-6779-4db0-b3f5-4ae3c9766583"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-29 06:26:51.313090: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-29 06:26:51.313141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-29 06:26:51.314446: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-29 06:26:51.321842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-29 06:26:52.483608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/exp/weights/best.pt, cfg=yolov9-e.yaml, data=/content/dataset/football-players-yolo/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=5, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=., name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir .', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/exp/weights/best.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/football-players-yolo/train.cache... 662 images, 0 backgrounds, 0 corrupt: 100% 662/662 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/football-players-yolo/val.cache... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<?, ?it/s]\n","Plotting labels to exp3/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mexp3\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        0/4      6.72G      1.662     0.8452       1.07        456        640:   0% 0/67 [00:02<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","        0/4      11.1G      1.476     0.7118      1.037         52        640: 100% 67/67 [01:08<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/4      12.3G      1.618     0.7554      1.042         95        640: 100% 67/67 [00:54<00:00,  1.24it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/4      12.3G      1.687     0.7795      1.044         77        640: 100% 67/67 [00:53<00:00,  1.24it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/4      12.3G      1.627     0.7469      1.038         81        640: 100% 67/67 [00:53<00:00,  1.26it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        4/4      12.3G      1.563     0.7155      1.035         91        640: 100% 67/67 [00:53<00:00,  1.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.92it/s]\n","                   all          1         22      0.997      0.955      0.993      0.769\n","\n","5 epochs completed in 0.084 hours.\n","Optimizer stripped from exp3/weights/last.pt, 139.9MB\n","Optimizer stripped from exp3/weights/best.pt, 139.9MB\n","\n","Validating exp3/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.18it/s]\n","                   all          1         22      0.997      0.955      0.993      0.766\n","Results saved to \u001b[1mexp3\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"exp3\"\n","!zip -r {DRIVE}/football-10e.zip {HOME}/$results_saved_to"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nov4q6nNQ-9H","executionInfo":{"status":"ok","timestamp":1716964351972,"user_tz":-120,"elapsed":15139,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"ab4c2911-fdb4-4552-eecd-d42dde72184f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/exp3/ (stored 0%)\n","  adding: content/exp3/train_batch0.jpg (deflated 7%)\n","  adding: content/exp3/F1_curve.png (deflated 17%)\n","  adding: content/exp3/labels.jpg (deflated 29%)\n","  adding: content/exp3/weights/ (stored 0%)\n","  adding: content/exp3/weights/last.pt (deflated 8%)\n","  adding: content/exp3/weights/best.pt (deflated 8%)\n","  adding: content/exp3/R_curve.png (deflated 17%)\n","  adding: content/exp3/events.out.tfevents.1716964013.faccc4e149c6.5438.0 (deflated 19%)\n","  adding: content/exp3/confusion_matrix.png (deflated 41%)\n","  adding: content/exp3/labels_correlogram.jpg (deflated 30%)\n","  adding: content/exp3/P_curve.png (deflated 24%)\n","  adding: content/exp3/PR_curve.png (deflated 30%)\n","  adding: content/exp3/hyp.yaml (deflated 43%)\n","  adding: content/exp3/train_batch1.jpg (deflated 16%)\n","  adding: content/exp3/train_batch2.jpg (deflated 11%)\n","  adding: content/exp3/results.csv (deflated 83%)\n","  adding: content/exp3/val_batch0_labels.jpg (deflated 7%)\n","  adding: content/exp3/val_batch0_pred.jpg (deflated 7%)\n","  adding: content/exp3/opt.yaml (deflated 49%)\n","  adding: content/exp3/results.png (deflated 13%)\n"]}]},{"cell_type":"markdown","source":["## PRW"],"metadata":{"id":"-6BK_WcURa_A"}},{"cell_type":"code","source":["!unzip -n -q {DRIVE}/datasets/PRW-yolo.zip -d {HOME}/dataset"],"metadata":{"id":"JbfvEcm_Red7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","\n","labels_path = '/content/dataset/PRW-yolo/labels'\n","output_path = '/content/dataset/PRW-yolo'\n","\n","# Ratios for splitting the datasets\n","train_ratio = 1\n","val_ratio = 0\n","\n","# test_ratio is implicitly determined\n","\n","# Get all file names without their extensions\n","filenames = [os.path.splitext(file)[0] for file in os.listdir(labels_path) if os.path.isfile(os.path.join(labels_path, file))]\n","\n","# Shuffle the list of filenames to ensure random distribution\n","random.shuffle(filenames)\n","\n","# Calculate split indices\n","no_total_files = len(filenames)\n","train_end = int(no_total_files * train_ratio)\n","print(train_end)\n","print(no_total_files)\n","\n","if(no_total_files == train_end):\n","  train_end-=1\n","\n","val_end = train_end + int(no_total_files * val_ratio) +1\n","\n","# Split the filenames\n","train_filenames = filenames[:train_end]\n","val_filenames = filenames[train_end:val_end]\n","test_filenames = filenames[val_end:]\n","print(val_filenames)\n","\n","# Function to write filenames to a file\n","def write_filenames_to_file(filenames, file_path):\n","    with open(file_path, 'w') as file:\n","        for name in filenames:\n","            file.write(f'./images/{name}.jpg\\n')\n","\n","# Write the splits to their respective files\n","write_filenames_to_file(train_filenames, os.path.join(output_path, 'train.txt'))\n","write_filenames_to_file(val_filenames, os.path.join(output_path, 'val.txt'))\n","write_filenames_to_file(test_filenames, os.path.join(output_path, 'test.txt'))\n","\n","print(\"Files have been split and saved successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjch_05eRqBI","executionInfo":{"status":"ok","timestamp":1716964643598,"user_tz":-120,"elapsed":10,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"dddacbf4-39fc-44ce-9f0b-2f9839ec3325"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11816\n","11816\n","['c3s1_117783']\n","Files have been split and saved successfully.\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/datasets/PRW-5e.pt /content/weights/PRW-5e.pt"],"metadata":{"id":"U_g2x7SQEjNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch -1 \\\n","--epochs 5 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project . \\\n","--single-cls \\\n","--noval \\\n","--weights /content/weights/PRW-5e.pt \\\n","--freeze 28\n","\n","# --device cpu \\\n","# --close-mosaic 15 \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TzkhuuaXbsJ","executionInfo":{"status":"ok","timestamp":1716969249155,"user_tz":-120,"elapsed":4483014,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"55936ae7-77b3-42f8-b482-f78902d9aba7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-29 06:39:30.465371: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-29 06:39:30.465427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-29 06:39:30.466927: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-29 06:39:30.474190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-29 06:39:31.639946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/weights/PRW-5e.pt, cfg=yolov9-e.yaml, data=/content/yolov9-masterthesis/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=5, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=., name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir .', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/weights/PRW-5e.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.75G total, 0.54G reserved, 0.53G allocated, 13.68G free\n","      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n","    69407846       244.8         1.718         112.4           nan        (1, 3, 640, 640)                    list\n","    69407846       489.7         2.674         100.6           nan        (2, 3, 640, 640)                    list\n","    69407846       979.4         4.977           153           nan        (4, 3, 640, 640)                    list\n","    69407846        1959         8.680         301.9           nan        (8, 3, 640, 640)                    list\n","CUDA out of memory. Tried to allocate 50.00 MiB. GPU \n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 10 for CUDA:0 11.82G/14.75G (80%) âœ…\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/PRW-yolo/train... 11815 images, 1 backgrounds, 0 corrupt: 100% 11815/11815 [00:01<00:00, 6983.73it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/dataset/PRW-yolo/images/c6s1_000476.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/PRW-yolo/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/PRW-yolo/val... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<00:00, 29.26it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/PRW-yolo/val.cache\n","Plotting labels to exp4/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mexp4\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        0/4      9.67G      1.324     0.7377      1.309         89        640:   0% 0/1182 [00:01<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","        0/4      9.82G      1.394     0.6857       1.27         64        640: 100% 1182/1182 [15:25<00:00,  1.28it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/4      9.82G      1.394     0.6944      1.272         38        640: 100% 1182/1182 [14:44<00:00,  1.34it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/4      9.82G       1.41      0.712      1.274         40        640: 100% 1182/1182 [14:33<00:00,  1.35it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/4      9.82G      1.396     0.7012       1.27         19        640: 100% 1182/1182 [14:31<00:00,  1.36it/s]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        4/4      9.82G      1.386     0.6894      1.267         26        640: 100% 1182/1182 [14:31<00:00,  1.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.63it/s]\n","                   all          1          2          1      0.993      0.995      0.803\n","\n","5 epochs completed in 1.235 hours.\n","Optimizer stripped from exp4/weights/last.pt, 139.9MB\n","Optimizer stripped from exp4/weights/best.pt, 139.9MB\n","\n","Validating exp4/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.05it/s]\n","                   all          1          2          1      0.992      0.995      0.803\n","Results saved to \u001b[1mexp4\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"exp4\"\n","!zip -r {DRIVE}/PRW-5e.zip {HOME}/$results_saved_to"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWNaX-HmXdjZ","executionInfo":{"status":"ok","timestamp":1716969264921,"user_tz":-120,"elapsed":15778,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"0c390e28-719d-4726-e737-2bb9d9d50290"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/exp4/ (stored 0%)\n","  adding: content/exp4/train_batch0.jpg (deflated 7%)\n","  adding: content/exp4/events.out.tfevents.1716964772.faccc4e149c6.8833.0 (deflated 18%)\n","  adding: content/exp4/F1_curve.png (deflated 17%)\n","  adding: content/exp4/labels.jpg (deflated 35%)\n","  adding: content/exp4/weights/ (stored 0%)\n","  adding: content/exp4/weights/last.pt (deflated 8%)\n","  adding: content/exp4/weights/best.pt (deflated 8%)\n","  adding: content/exp4/R_curve.png (deflated 19%)\n","  adding: content/exp4/confusion_matrix.png (deflated 43%)\n","  adding: content/exp4/labels_correlogram.jpg (deflated 33%)\n","  adding: content/exp4/P_curve.png (deflated 21%)\n","  adding: content/exp4/PR_curve.png (deflated 29%)\n","  adding: content/exp4/hyp.yaml (deflated 43%)\n","  adding: content/exp4/train_batch1.jpg (deflated 17%)\n","  adding: content/exp4/train_batch2.jpg (deflated 11%)\n","  adding: content/exp4/results.csv (deflated 83%)\n","  adding: content/exp4/val_batch0_labels.jpg (deflated 7%)\n","  adding: content/exp4/val_batch0_pred.jpg (deflated 7%)\n","  adding: content/exp4/opt.yaml (deflated 49%)\n","  adding: content/exp4/results.png (deflated 12%)\n"]}]},{"cell_type":"markdown","source":["# FIMUS resume training until 50 and 100 epochs"],"metadata":{"id":"HbwMzO4YHmoO"}},{"cell_type":"code","source":["!unzip -n -q {DRIVE}/FIMUSDataset/Inconsistent.zip -d {HOME}/dataset"],"metadata":{"id":"4otaa4VeHi8u","executionInfo":{"status":"ok","timestamp":1717071326901,"user_tz":-120,"elapsed":69418,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","\n","labels_path = '/content/dataset/Inconsistent/labels'\n","output_path = '/content/dataset/Inconsistent'\n","\n","# Ratios for splitting the datasets\n","train_ratio = 1\n","val_ratio = 0\n","\n","# test_ratio is implicitly determined\n","\n","# Get all file names without their extensions\n","filenames = [os.path.splitext(file)[0] for file in os.listdir(labels_path) if os.path.isfile(os.path.join(labels_path, file))]\n","\n","# Shuffle the list of filenames to ensure random distribution\n","random.shuffle(filenames)\n","\n","# Calculate split indices\n","no_total_files = len(filenames)\n","train_end = int(no_total_files * train_ratio)\n","print(train_end)\n","print(no_total_files)\n","\n","if(no_total_files == train_end):\n","  train_end-=1\n","\n","val_end = train_end + int(no_total_files * val_ratio) +1\n","\n","# Split the filenames\n","train_filenames = filenames[:train_end]\n","val_filenames = filenames[train_end:val_end]\n","test_filenames = filenames[val_end:]\n","print(val_filenames)\n","\n","# Function to write filenames to a file\n","def write_filenames_to_file(filenames, file_path):\n","    with open(file_path, 'w') as file:\n","        for name in filenames:\n","            file.write(f'./images/{name}.jpg\\n')\n","\n","# Write the splits to their respective files\n","write_filenames_to_file(train_filenames, os.path.join(output_path, 'train.txt'))\n","write_filenames_to_file(val_filenames, os.path.join(output_path, 'val.txt'))\n","write_filenames_to_file(test_filenames, os.path.join(output_path, 'test.txt'))\n","\n","print(\"Files have been split and saved successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wRLuiU7HwwG","executionInfo":{"status":"ok","timestamp":1717071326901,"user_tz":-120,"elapsed":6,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"8cc3279a-31aa-4c52-9310-024fbf3953ae"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2637\n","2637\n","['120324-164120-right']\n","Files have been split and saved successfully.\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/FIMUSDataset/Inconsistent-50e.pt /content/weights/Inconsistent-50e.pt"],"metadata":{"id":"nWm9EvJHIF7u","executionInfo":{"status":"ok","timestamp":1717071336965,"user_tz":-120,"elapsed":7231,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 10 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/80e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/70e/exp/weights/best.pt \\\n","--freeze 28\n","\n","# --device cpu \\\n","# --close-mosaic 15 \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rArp0G1nM9gB","executionInfo":{"status":"ok","timestamp":1717082109009,"user_tz":-120,"elapsed":2919788,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"5a3a5502-e868-41a6-ea32-7b8ed26ed17c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-30 14:26:33.523083: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-30 14:26:33.523155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-30 14:26:33.524729: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-30 14:26:33.532259: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-30 14:26:34.709876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/70e/exp/weights/best.pt, cfg=yolov9-e.yaml, data=/content/yolov9-masterthesis/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=10, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=/content/80e, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/80e', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/70e/exp/weights/best.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/Inconsistent/train.cache... 2636 images, 111 backgrounds, 0 corrupt: 100% 2636/2636 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/Inconsistent/val.cache... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<?, ?it/s]\n","Plotting labels to /content/80e/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/80e/exp\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        0/9      6.02G      1.092     0.6164        1.4         19        640:   0% 0/264 [00:08<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","        0/9      7.43G     0.9876     0.5364      1.221         13        640: 100% 264/264 [04:58<00:00,  1.13s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/9      7.46G     0.9127     0.5068      1.186         17        640: 100% 264/264 [04:35<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/9      7.46G     0.8624     0.4856      1.168         11        640: 100% 264/264 [04:46<00:00,  1.09s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/9      7.46G     0.9241     0.5219      1.172         11        640: 100% 264/264 [04:42<00:00,  1.07s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        4/9      7.46G     0.9529     0.5446      1.191         12        640: 100% 264/264 [04:47<00:00,  1.09s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        5/9      7.46G     0.9447     0.5396      1.196         16        640: 100% 264/264 [04:41<00:00,  1.06s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        6/9      7.46G     0.9391     0.5308      1.199         15        640: 100% 264/264 [04:39<00:00,  1.06s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        7/9      7.46G     0.9126     0.5137      1.185          8        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        8/9      7.46G     0.9299     0.5153      1.187         17        640: 100% 264/264 [04:36<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        9/9      7.46G     0.9503     0.5179      1.207         11        640: 100% 264/264 [04:41<00:00,  1.07s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.13s/it]\n","                   all          1          1      0.973          1      0.995      0.895\n","\n","10 epochs completed in 0.803 hours.\n","Optimizer stripped from /content/80e/exp/weights/last.pt, 139.9MB\n","Optimizer stripped from /content/80e/exp/weights/best.pt, 139.9MB\n","\n","Validating /content/80e/exp/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.21it/s]\n","                   all          1          1      0.973          1      0.995      0.895\n","Results saved to \u001b[1m/content/80e/exp\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"80e/exp\"\n","!zip -r {DRIVE}/80e.zip {HOME}/$results_saved_to"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXIDV_H8btVG","executionInfo":{"status":"ok","timestamp":1717082125508,"user_tz":-120,"elapsed":15538,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"90f93751-a34c-4a81-b332-dbdd1a1666cc"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/80e/exp/ (stored 0%)\n","  adding: content/80e/exp/confusion_matrix.png (deflated 43%)\n","  adding: content/80e/exp/train_batch1.jpg (deflated 25%)\n","  adding: content/80e/exp/labels_correlogram.jpg (deflated 41%)\n","  adding: content/80e/exp/R_curve.png (deflated 24%)\n","  adding: content/80e/exp/PR_curve.png (deflated 29%)\n","  adding: content/80e/exp/weights/ (stored 0%)\n","  adding: content/80e/exp/weights/best.pt (deflated 8%)\n","  adding: content/80e/exp/weights/last.pt (deflated 8%)\n","  adding: content/80e/exp/val_batch0_pred.jpg (deflated 22%)\n","  adding: content/80e/exp/hyp.yaml (deflated 43%)\n","  adding: content/80e/exp/train_batch0.jpg (deflated 14%)\n","  adding: content/80e/exp/labels.jpg (deflated 33%)\n","  adding: content/80e/exp/P_curve.png (deflated 24%)\n","  adding: content/80e/exp/opt.yaml (deflated 50%)\n","  adding: content/80e/exp/results.csv (deflated 87%)\n","  adding: content/80e/exp/train_batch2.jpg (deflated 21%)\n","  adding: content/80e/exp/F1_curve.png (deflated 20%)\n","  adding: content/80e/exp/val_batch0_labels.jpg (deflated 22%)\n","  adding: content/80e/exp/events.out.tfevents.1717079195.68b1c5c90573.34903.0 (deflated 20%)\n","  adding: content/80e/exp/results.png (deflated 12%)\n"]}]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 10 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/90e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/80e/exp/weights/best.pt \\\n","--freeze 28\n","\n","# --device cpu \\\n","# --close-mosaic 15 \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cC6zuBX5ZWU","executionInfo":{"status":"ok","timestamp":1717084974986,"user_tz":-120,"elapsed":2849508,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"8853cf1b-8a49-47a0-de8b-db98ff2fa7da"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-30 15:15:29.183726: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-30 15:15:29.183779: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-30 15:15:29.185115: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-30 15:15:29.192802: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-30 15:15:30.448814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/80e/exp/weights/best.pt, cfg=yolov9-e.yaml, data=/content/yolov9-masterthesis/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=10, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=/content/90e, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/90e', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/80e/exp/weights/best.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/Inconsistent/train.cache... 2636 images, 111 backgrounds, 0 corrupt: 100% 2636/2636 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/Inconsistent/val.cache... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<?, ?it/s]\n","Plotting labels to /content/90e/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/90e/exp\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        0/9      6.02G      1.056     0.6353      1.397         19        640:   0% 0/264 [00:08<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","        0/9      7.43G     0.9666     0.5166      1.207         13        640: 100% 264/264 [04:47<00:00,  1.09s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/9      7.46G      0.867     0.4765      1.165         17        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/9      7.46G     0.8131     0.4566      1.143         11        640: 100% 264/264 [04:30<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/9      7.46G     0.8762     0.4912      1.149         11        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        4/9      7.46G     0.9033     0.5123      1.161         12        640: 100% 264/264 [04:36<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        5/9      7.46G     0.8914     0.5034       1.17         16        640: 100% 264/264 [04:30<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        6/9      7.46G     0.8912     0.5099      1.176         15        640: 100% 264/264 [04:39<00:00,  1.06s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        7/9      7.46G      0.875     0.4866      1.168          8        640: 100% 264/264 [04:35<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        8/9      7.46G     0.8909     0.4902      1.174         17        640: 100% 264/264 [04:32<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        9/9      7.46G     0.9282     0.5117      1.192         11        640: 100% 264/264 [04:36<00:00,  1.05s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.27s/it]\n","                   all          1          1      0.973          1      0.995      0.995\n","\n","10 epochs completed in 0.784 hours.\n","Optimizer stripped from /content/90e/exp/weights/last.pt, 139.9MB\n","Optimizer stripped from /content/90e/exp/weights/best.pt, 139.9MB\n","\n","Validating /content/90e/exp/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.48it/s]\n","                   all          1          1      0.973          1      0.995      0.995\n","Results saved to \u001b[1m/content/90e/exp\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"90e/exp\"\n","!zip -r {DRIVE}/90e.zip {HOME}/$results_saved_to"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGi54bnB5snk","executionInfo":{"status":"ok","timestamp":1717084990028,"user_tz":-120,"elapsed":15054,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"ead52093-2b60-43e2-b5df-cad034420393"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/90e/exp/ (stored 0%)\n","  adding: content/90e/exp/confusion_matrix.png (deflated 43%)\n","  adding: content/90e/exp/train_batch1.jpg (deflated 25%)\n","  adding: content/90e/exp/labels_correlogram.jpg (deflated 41%)\n","  adding: content/90e/exp/R_curve.png (deflated 22%)\n","  adding: content/90e/exp/PR_curve.png (deflated 30%)\n","  adding: content/90e/exp/weights/ (stored 0%)\n","  adding: content/90e/exp/weights/best.pt (deflated 8%)\n","  adding: content/90e/exp/weights/last.pt (deflated 8%)\n","  adding: content/90e/exp/val_batch0_pred.jpg (deflated 22%)\n","  adding: content/90e/exp/hyp.yaml (deflated 43%)\n","  adding: content/90e/exp/events.out.tfevents.1717082131.68b1c5c90573.47525.0 (deflated 20%)\n","  adding: content/90e/exp/train_batch0.jpg (deflated 14%)\n","  adding: content/90e/exp/labels.jpg (deflated 33%)\n","  adding: content/90e/exp/P_curve.png (deflated 22%)\n","  adding: content/90e/exp/opt.yaml (deflated 50%)\n","  adding: content/90e/exp/results.csv (deflated 87%)\n","  adding: content/90e/exp/train_batch2.jpg (deflated 21%)\n","  adding: content/90e/exp/F1_curve.png (deflated 18%)\n","  adding: content/90e/exp/val_batch0_labels.jpg (deflated 22%)\n","  adding: content/90e/exp/results.png (deflated 12%)\n"]}]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 10 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/100e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/90e/exp/weights/best.pt \\\n","--freeze 28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0vCJK_O5rRW","executionInfo":{"status":"ok","timestamp":1717087813884,"user_tz":-120,"elapsed":2823888,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"04675098-61e6-4b03-ccff-aff7e924aff1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-30 16:03:13.759843: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-30 16:03:13.759900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-30 16:03:13.761405: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-30 16:03:13.768486: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-30 16:03:14.940585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/90e/exp/weights/best.pt, cfg=yolov9-e.yaml, data=/content/yolov9-masterthesis/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=10, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=/content/100e, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/100e', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/90e/exp/weights/best.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/Inconsistent/train.cache... 2636 images, 111 backgrounds, 0 corrupt: 100% 2636/2636 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/Inconsistent/val.cache... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<?, ?it/s]\n","Plotting labels to /content/100e/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/100e/exp\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        0/9      6.02G      1.072     0.5681      1.371         19        640:   0% 0/264 [00:07<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","        0/9      7.43G     0.9466     0.5006      1.201         13        640: 100% 264/264 [04:45<00:00,  1.08s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/9      7.46G     0.8291     0.4587      1.148         17        640: 100% 264/264 [04:32<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/9      7.46G     0.7629     0.4301      1.124         11        640: 100% 264/264 [04:28<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/9      7.46G     0.8267     0.4618      1.129         11        640: 100% 264/264 [04:29<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        4/9      7.46G     0.8646     0.4864      1.144         12        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        5/9      7.46G     0.8578     0.4787      1.154         16        640: 100% 264/264 [04:28<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        6/9      7.46G     0.8605     0.4822      1.162         15        640: 100% 264/264 [04:32<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        7/9      7.46G     0.8407     0.4734      1.152          8        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        8/9      7.46G     0.8636     0.4764      1.164         17        640: 100% 264/264 [04:27<00:00,  1.01s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        9/9      7.46G     0.9107     0.4962      1.189         11        640: 100% 264/264 [04:38<00:00,  1.06s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.33s/it]\n","                   all          1          1      0.972          1      0.995      0.895\n","\n","10 epochs completed in 0.777 hours.\n","Optimizer stripped from /content/100e/exp/weights/last.pt, 139.9MB\n","Optimizer stripped from /content/100e/exp/weights/best.pt, 139.9MB\n","\n","Validating /content/100e/exp/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.56it/s]\n","                   all          1          1      0.972          1      0.995      0.895\n","Results saved to \u001b[1m/content/100e/exp\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"100e/exp\"\n","!zip -r {DRIVE}/100e.zip {HOME}/$results_saved_to"],"metadata":{"id":"JxZbbP9dDqus","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717087828847,"user_tz":-120,"elapsed":14969,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"a5361062-a7ce-4429-89b8-5a01807e8964"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/100e/exp/ (stored 0%)\n","  adding: content/100e/exp/confusion_matrix.png (deflated 43%)\n","  adding: content/100e/exp/events.out.tfevents.1717084996.68b1c5c90573.59839.0 (deflated 20%)\n","  adding: content/100e/exp/train_batch1.jpg (deflated 25%)\n","  adding: content/100e/exp/labels_correlogram.jpg (deflated 41%)\n","  adding: content/100e/exp/R_curve.png (deflated 23%)\n","  adding: content/100e/exp/PR_curve.png (deflated 27%)\n","  adding: content/100e/exp/weights/ (stored 0%)\n","  adding: content/100e/exp/weights/best.pt (deflated 8%)\n","  adding: content/100e/exp/weights/last.pt (deflated 8%)\n","  adding: content/100e/exp/val_batch0_pred.jpg (deflated 22%)\n","  adding: content/100e/exp/hyp.yaml (deflated 43%)\n","  adding: content/100e/exp/train_batch0.jpg (deflated 14%)\n","  adding: content/100e/exp/labels.jpg (deflated 33%)\n","  adding: content/100e/exp/P_curve.png (deflated 21%)\n","  adding: content/100e/exp/opt.yaml (deflated 50%)\n","  adding: content/100e/exp/results.csv (deflated 87%)\n","  adding: content/100e/exp/train_batch2.jpg (deflated 21%)\n","  adding: content/100e/exp/F1_curve.png (deflated 19%)\n","  adding: content/100e/exp/val_batch0_labels.jpg (deflated 22%)\n","  adding: content/100e/exp/results.png (deflated 12%)\n"]}]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 25 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/125e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/100e/exp/weights/best.pt \\\n","--freeze 28"],"metadata":{"id":"UugPJJ91443h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717094869624,"user_tz":-120,"elapsed":7038897,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"5221d2d8-6b04-4965-b34b-d41cfa09e0f5"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-30 16:50:34.260224: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-30 16:50:34.260274: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-30 16:50:34.261611: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-30 16:50:34.270221: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-30 16:50:35.554702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/100e/exp/weights/best.pt, cfg=yolov9-e.yaml, data=/content/yolov9-masterthesis/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=25, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=/content/125e, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/125e', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/100e/exp/weights/best.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/Inconsistent/train.cache... 2636 images, 111 backgrounds, 0 corrupt: 100% 2636/2636 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/Inconsistent/val.cache... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<?, ?it/s]\n","Plotting labels to /content/125e/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/125e/exp\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       0/24      6.02G      1.045     0.5392      1.358         19        640:   0% 0/264 [00:07<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","       0/24      7.43G     0.9315     0.4949      1.196         13        640: 100% 264/264 [04:46<00:00,  1.08s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/24      7.46G     0.8091     0.4487      1.137         17        640: 100% 264/264 [04:29<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/24      7.46G     0.7421     0.4204      1.111         11        640: 100% 264/264 [04:30<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/24      7.46G     0.8192     0.4627      1.127         11        640: 100% 264/264 [04:29<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/24      7.46G     0.8594      0.493      1.146         12        640: 100% 264/264 [04:37<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/24      7.46G     0.8672      0.499      1.159         16        640: 100% 264/264 [04:32<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/24      7.46G     0.8898     0.5102      1.174         15        640: 100% 264/264 [04:39<00:00,  1.06s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/24      7.46G       0.89     0.5106      1.174          8        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/24      7.46G     0.9446     0.5311      1.194         17        640: 100% 264/264 [04:30<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/24      7.46G     0.9996     0.5622      1.223         11        640: 100% 264/264 [04:36<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/24      7.46G      1.068     0.6037      1.253         16        640: 100% 264/264 [04:28<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/24      7.46G       1.07     0.6102      1.268         15        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/24      7.46G      1.045     0.5957      1.255         18        640: 100% 264/264 [04:37<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/24      7.46G      1.045     0.5884       1.25         10        640: 100% 264/264 [04:36<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/24      7.46G      1.032     0.5827      1.233         14        640: 100% 264/264 [04:32<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/24      7.46G      1.019      0.583      1.239         19        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/24      7.46G      1.034     0.5724      1.241          7        640: 100% 264/264 [04:35<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/24      7.46G     0.9937     0.5539      1.211         11        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/24      7.46G     0.9957      0.546      1.227         23        640: 100% 264/264 [04:28<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/24      7.46G     0.9949     0.5464      1.222         16        640: 100% 264/264 [04:36<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/24      7.46G     0.9836      0.529      1.227         13        640: 100% 264/264 [04:28<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/24      7.46G      0.988     0.5403       1.23         11        640: 100% 264/264 [04:39<00:00,  1.06s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/24      7.46G     0.9793     0.5355      1.227         20        640: 100% 264/264 [04:36<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/24      7.46G     0.9834     0.5542       1.22         16        640: 100% 264/264 [04:39<00:00,  1.06s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/24      7.46G     0.9483      0.519      1.207         14        640: 100% 264/264 [04:30<00:00,  1.02s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.83s/it]\n","                   all          1          1      0.973          1      0.995      0.995\n","\n","25 epochs completed in 1.947 hours.\n","Optimizer stripped from /content/125e/exp/weights/last.pt, 139.9MB\n","Optimizer stripped from /content/125e/exp/weights/best.pt, 139.9MB\n","\n","Validating /content/125e/exp/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.42it/s]\n","                   all          1          1      0.973          1      0.995      0.995\n","Results saved to \u001b[1m/content/125e/exp\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"125e/exp\"\n","!zip -r {DRIVE}/125e.zip {HOME}/$results_saved_to"],"metadata":{"id":"f5_ZTH9q453r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717094885115,"user_tz":-120,"elapsed":15503,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"bc935f9e-c36f-45e3-c304-4a691fe47fa7"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/125e/exp/ (stored 0%)\n","  adding: content/125e/exp/confusion_matrix.png (deflated 43%)\n","  adding: content/125e/exp/train_batch1.jpg (deflated 25%)\n","  adding: content/125e/exp/labels_correlogram.jpg (deflated 41%)\n","  adding: content/125e/exp/R_curve.png (deflated 23%)\n","  adding: content/125e/exp/PR_curve.png (deflated 27%)\n","  adding: content/125e/exp/weights/ (stored 0%)\n","  adding: content/125e/exp/weights/best.pt (deflated 8%)\n","  adding: content/125e/exp/weights/last.pt (deflated 8%)\n","  adding: content/125e/exp/val_batch0_pred.jpg (deflated 22%)\n","  adding: content/125e/exp/hyp.yaml (deflated 43%)\n","  adding: content/125e/exp/events.out.tfevents.1717087836.68b1c5c90573.72056.0 (deflated 21%)\n","  adding: content/125e/exp/train_batch0.jpg (deflated 14%)\n","  adding: content/125e/exp/labels.jpg (deflated 33%)\n","  adding: content/125e/exp/P_curve.png (deflated 22%)\n","  adding: content/125e/exp/opt.yaml (deflated 50%)\n","  adding: content/125e/exp/results.csv (deflated 90%)\n","  adding: content/125e/exp/train_batch2.jpg (deflated 21%)\n","  adding: content/125e/exp/F1_curve.png (deflated 19%)\n","  adding: content/125e/exp/val_batch0_labels.jpg (deflated 22%)\n","  adding: content/125e/exp/results.png (deflated 13%)\n"]}]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 25 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/150e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/125e/exp/weights/best.pt \\\n","--freeze 28"],"metadata":{"id":"xqouSxVc46yO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717101918555,"user_tz":-120,"elapsed":7033456,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"c50c3035-ec0f-4d74-a04d-71807132c178"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-30 18:48:08.338077: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-30 18:48:08.338129: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-30 18:48:08.339569: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-30 18:48:08.347273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-30 18:48:09.527928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/125e/exp/weights/best.pt, cfg=yolov9-e.yaml, data=/content/yolov9-masterthesis/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=25, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=/content/150e, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/150e', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/125e/exp/weights/best.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/Inconsistent/train.cache... 2636 images, 111 backgrounds, 0 corrupt: 100% 2636/2636 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/Inconsistent/val.cache... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<?, ?it/s]\n","Plotting labels to /content/150e/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/150e/exp\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       0/24      6.02G      1.023     0.5974      1.379         19        640:   0% 0/264 [00:06<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","       0/24      7.43G      0.919     0.4939      1.187         13        640: 100% 264/264 [04:47<00:00,  1.09s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/24      7.46G     0.8395     0.4657      1.153         17        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/24      7.46G     0.7823     0.4434      1.126         11        640: 100% 264/264 [04:33<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/24      7.46G     0.8475     0.4821      1.136         11        640: 100% 264/264 [04:30<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/24      7.46G     0.8653      0.494      1.149         12        640: 100% 264/264 [04:38<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/24      7.46G      0.864     0.4956      1.159         16        640: 100% 264/264 [04:33<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/24      7.46G       0.88     0.5021      1.175         15        640: 100% 264/264 [04:35<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/24      7.46G     0.8705     0.4932      1.164          8        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/24      7.46G     0.9096     0.5091      1.177         17        640: 100% 264/264 [04:32<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/24      7.46G     0.9414     0.5225      1.198         11        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/24      7.46G     0.9826     0.5522       1.21         16        640: 100% 264/264 [04:32<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/24      7.46G     0.9866     0.5528      1.229         15        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/24      7.46G     0.9796     0.5464      1.221         18        640: 100% 264/264 [04:31<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/24      7.46G     0.9726     0.5432      1.224         10        640: 100% 264/264 [04:31<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/24      7.46G     0.9657     0.5395      1.202         14        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/24      7.46G     0.9577     0.5356      1.212         19        640: 100% 264/264 [04:28<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/24      7.46G     0.9728     0.5278      1.214          7        640: 100% 264/264 [04:30<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/24      7.46G     0.9442     0.5195      1.194         11        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/24      7.46G     0.9417     0.5146      1.202         23        640: 100% 264/264 [04:29<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/24      7.46G     0.9444     0.5158      1.199         16        640: 100% 264/264 [04:30<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/24      7.46G     0.9386     0.5047      1.205         13        640: 100% 264/264 [04:26<00:00,  1.01s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/24      7.46G     0.9486     0.5107      1.208         11        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/24      7.46G     0.9486     0.5125      1.211         20        640: 100% 264/264 [04:37<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/24      7.46G     0.9512     0.5302      1.208         16        640: 100% 264/264 [04:35<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/24      7.46G     0.9251     0.4982      1.198         14        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.19s/it]\n","                   all          1          1      0.973          1      0.995      0.995\n","\n","25 epochs completed in 1.946 hours.\n","Optimizer stripped from /content/150e/exp/weights/last.pt, 139.9MB\n","Optimizer stripped from /content/150e/exp/weights/best.pt, 139.9MB\n","\n","Validating /content/150e/exp/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.37it/s]\n","                   all          1          1      0.973          1      0.995      0.895\n","Results saved to \u001b[1m/content/150e/exp\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"150e/exp\"\n","!zip -r {DRIVE}/150e.zip {HOME}/$results_saved_to"],"metadata":{"id":"r65DnGui47m-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717101933571,"user_tz":-120,"elapsed":15025,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"8776067e-46c8-455b-d422-9ac99fef5c48"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/150e/exp/ (stored 0%)\n","  adding: content/150e/exp/confusion_matrix.png (deflated 43%)\n","  adding: content/150e/exp/train_batch1.jpg (deflated 25%)\n","  adding: content/150e/exp/events.out.tfevents.1717094890.68b1c5c90573.102163.0 (deflated 21%)\n","  adding: content/150e/exp/labels_correlogram.jpg (deflated 41%)\n","  adding: content/150e/exp/R_curve.png (deflated 23%)\n","  adding: content/150e/exp/PR_curve.png (deflated 30%)\n","  adding: content/150e/exp/weights/ (stored 0%)\n","  adding: content/150e/exp/weights/best.pt (deflated 8%)\n","  adding: content/150e/exp/weights/last.pt (deflated 8%)\n","  adding: content/150e/exp/val_batch0_pred.jpg (deflated 22%)\n","  adding: content/150e/exp/hyp.yaml (deflated 43%)\n","  adding: content/150e/exp/train_batch0.jpg (deflated 14%)\n","  adding: content/150e/exp/labels.jpg (deflated 33%)\n","  adding: content/150e/exp/P_curve.png (deflated 22%)\n","  adding: content/150e/exp/opt.yaml (deflated 50%)\n","  adding: content/150e/exp/results.csv (deflated 90%)\n","  adding: content/150e/exp/train_batch2.jpg (deflated 21%)\n","  adding: content/150e/exp/F1_curve.png (deflated 19%)\n","  adding: content/150e/exp/val_batch0_labels.jpg (deflated 22%)\n","  adding: content/150e/exp/results.png (deflated 13%)\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/FIMUSDataset/Inconsistent-20e.pt /content/weights/Inconsistent-20e.pt"],"metadata":{"id":"fPWvIYyH0HtL","executionInfo":{"status":"ok","timestamp":1717101941137,"user_tz":-120,"elapsed":6052,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 10 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/30e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/weights/Inconsistent-20e.pt \\\n","--freeze 28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovL6GL2U4BhF","executionInfo":{"status":"ok","timestamp":1717104889139,"user_tz":-120,"elapsed":2948032,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"57012338-c8da-4136-8108-ee7a6ffa1f7b"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-30 20:45:44.849381: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-30 20:45:44.849440: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-30 20:45:44.851001: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-30 20:45:44.859048: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-30 20:45:45.977668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/weights/Inconsistent-20e.pt, cfg=yolov9-e.yaml, data=/content/yolov9-masterthesis/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=10, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=/content/30e, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/30e', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/weights/Inconsistent-20e.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/Inconsistent/train.cache... 2636 images, 111 backgrounds, 0 corrupt: 100% 2636/2636 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/Inconsistent/val.cache... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<?, ?it/s]\n","Plotting labels to /content/30e/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/30e/exp\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        0/9      6.02G      1.116     0.6788      1.408         19        640:   0% 0/264 [00:08<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","        0/9      7.43G      1.104     0.6189       1.27         13        640: 100% 264/264 [04:45<00:00,  1.08s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/9      7.46G      1.134     0.6571       1.28         17        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/9      7.46G      1.174     0.6929      1.305         11        640: 100% 264/264 [04:26<00:00,  1.01s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/9      7.46G      1.256     0.7586      1.325         11        640: 100% 264/264 [04:37<00:00,  1.05s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        4/9      7.46G      1.258      0.779      1.335         12        640: 100% 264/264 [04:51<00:00,  1.10s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        5/9      7.46G      1.215     0.7404      1.325         16        640: 100% 264/264 [04:55<00:00,  1.12s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        6/9      7.46G      1.193      0.719      1.316         15        640: 100% 264/264 [04:58<00:00,  1.13s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        7/9      7.46G      1.142     0.6818      1.288          8        640: 100% 264/264 [04:56<00:00,  1.12s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        8/9      7.46G      1.128     0.6629      1.285         17        640: 100% 264/264 [04:47<00:00,  1.09s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        9/9      7.46G      1.103     0.6399      1.276         11        640: 100% 264/264 [04:43<00:00,  1.07s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.45s/it]\n","                   all          1          1      0.972          1      0.995      0.895\n","\n","10 epochs completed in 0.811 hours.\n","Optimizer stripped from /content/30e/exp/weights/last.pt, 139.9MB\n","Optimizer stripped from /content/30e/exp/weights/best.pt, 139.9MB\n","\n","Validating /content/30e/exp/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.29it/s]\n","                   all          1          1      0.972          1      0.995      0.895\n","Results saved to \u001b[1m/content/30e/exp\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"30e/exp\"\n","!zip -r {DRIVE}/30e.zip {HOME}/$results_saved_to"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGMUnhWa4FIR","executionInfo":{"status":"ok","timestamp":1717104904282,"user_tz":-120,"elapsed":15153,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"731e60dd-b95b-47b9-d05a-317b04cd843a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/30e/exp/ (stored 0%)\n","  adding: content/30e/exp/confusion_matrix.png (deflated 43%)\n","  adding: content/30e/exp/train_batch1.jpg (deflated 25%)\n","  adding: content/30e/exp/labels_correlogram.jpg (deflated 41%)\n","  adding: content/30e/exp/R_curve.png (deflated 23%)\n","  adding: content/30e/exp/PR_curve.png (deflated 29%)\n","  adding: content/30e/exp/weights/ (stored 0%)\n","  adding: content/30e/exp/weights/best.pt (deflated 8%)\n","  adding: content/30e/exp/weights/last.pt (deflated 8%)\n","  adding: content/30e/exp/val_batch0_pred.jpg (deflated 22%)\n","  adding: content/30e/exp/events.out.tfevents.1717101946.68b1c5c90573.132286.0 (deflated 20%)\n","  adding: content/30e/exp/hyp.yaml (deflated 43%)\n","  adding: content/30e/exp/train_batch0.jpg (deflated 14%)\n","  adding: content/30e/exp/labels.jpg (deflated 33%)\n","  adding: content/30e/exp/P_curve.png (deflated 22%)\n","  adding: content/30e/exp/opt.yaml (deflated 50%)\n","  adding: content/30e/exp/results.csv (deflated 87%)\n","  adding: content/30e/exp/train_batch2.jpg (deflated 21%)\n","  adding: content/30e/exp/F1_curve.png (deflated 20%)\n","  adding: content/30e/exp/val_batch0_labels.jpg (deflated 22%)\n","  adding: content/30e/exp/results.png (deflated 13%)\n"]}]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 10 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/40e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/30e/exp/weights/best.pt \\\n","--freeze 28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUopDPvC4KEc","executionInfo":{"status":"ok","timestamp":1717107739635,"user_tz":-120,"elapsed":2835385,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"cb6a2e24-be4b-411e-8d8a-e65997d83907"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","2024-05-30 21:35:07.957411: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-30 21:35:07.957466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-30 21:35:07.958832: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-30 21:35:07.966215: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-30 21:35:09.163787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/30e/exp/weights/best.pt, cfg=yolov9-e.yaml, data=/content/yolov9-masterthesis/data.yaml, hyp=yolov9-masterthesis/data/hyps/hyp.scratch-high.yaml, epochs=10, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=True, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=/content/40e, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[28], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ v3.0-4-g3c5307c Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/40e', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10982822  models.yolo.DualDDetect                 [1, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69407846 parameters, 69407814 gradients, 244.8 GFLOPs\n","\n","Transferred 2172/2172 items from /content/30e/exp/weights/best.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.conv.weight\n","freezing model.2.bn.weight\n","freezing model.2.bn.bias\n","freezing model.3.cv1.conv.weight\n","freezing model.3.cv1.bn.weight\n","freezing model.3.cv1.bn.bias\n","freezing model.3.cv2.0.cv1.conv.weight\n","freezing model.3.cv2.0.cv1.bn.weight\n","freezing model.3.cv2.0.cv1.bn.bias\n","freezing model.3.cv2.0.cv2.conv.weight\n","freezing model.3.cv2.0.cv2.bn.weight\n","freezing model.3.cv2.0.cv2.bn.bias\n","freezing model.3.cv2.0.cv3.conv.weight\n","freezing model.3.cv2.0.cv3.bn.weight\n","freezing model.3.cv2.0.cv3.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.0.cv2.conv.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.weight\n","freezing model.3.cv2.0.m.0.cv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv2.0.m.1.cv2.conv.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.weight\n","freezing model.3.cv2.0.m.1.cv2.bn.bias\n","freezing model.3.cv2.1.conv.weight\n","freezing model.3.cv2.1.bn.weight\n","freezing model.3.cv2.1.bn.bias\n","freezing model.3.cv3.0.cv1.conv.weight\n","freezing model.3.cv3.0.cv1.bn.weight\n","freezing model.3.cv3.0.cv1.bn.bias\n","freezing model.3.cv3.0.cv2.conv.weight\n","freezing model.3.cv3.0.cv2.bn.weight\n","freezing model.3.cv3.0.cv2.bn.bias\n","freezing model.3.cv3.0.cv3.conv.weight\n","freezing model.3.cv3.0.cv3.bn.weight\n","freezing model.3.cv3.0.cv3.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.0.cv2.conv.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.weight\n","freezing model.3.cv3.0.m.0.cv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.3.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.3.cv3.0.m.1.cv2.conv.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.weight\n","freezing model.3.cv3.0.m.1.cv2.bn.bias\n","freezing model.3.cv3.1.conv.weight\n","freezing model.3.cv3.1.bn.weight\n","freezing model.3.cv3.1.bn.bias\n","freezing model.3.cv4.conv.weight\n","freezing model.3.cv4.bn.weight\n","freezing model.3.cv4.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.5.cv1.conv.weight\n","freezing model.5.cv1.bn.weight\n","freezing model.5.cv1.bn.bias\n","freezing model.5.cv2.0.cv1.conv.weight\n","freezing model.5.cv2.0.cv1.bn.weight\n","freezing model.5.cv2.0.cv1.bn.bias\n","freezing model.5.cv2.0.cv2.conv.weight\n","freezing model.5.cv2.0.cv2.bn.weight\n","freezing model.5.cv2.0.cv2.bn.bias\n","freezing model.5.cv2.0.cv3.conv.weight\n","freezing model.5.cv2.0.cv3.bn.weight\n","freezing model.5.cv2.0.cv3.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.0.cv2.conv.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.weight\n","freezing model.5.cv2.0.m.0.cv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv2.0.m.1.cv2.conv.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.weight\n","freezing model.5.cv2.0.m.1.cv2.bn.bias\n","freezing model.5.cv2.1.conv.weight\n","freezing model.5.cv2.1.bn.weight\n","freezing model.5.cv2.1.bn.bias\n","freezing model.5.cv3.0.cv1.conv.weight\n","freezing model.5.cv3.0.cv1.bn.weight\n","freezing model.5.cv3.0.cv1.bn.bias\n","freezing model.5.cv3.0.cv2.conv.weight\n","freezing model.5.cv3.0.cv2.bn.weight\n","freezing model.5.cv3.0.cv2.bn.bias\n","freezing model.5.cv3.0.cv3.conv.weight\n","freezing model.5.cv3.0.cv3.bn.weight\n","freezing model.5.cv3.0.cv3.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.0.cv2.conv.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.weight\n","freezing model.5.cv3.0.m.0.cv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.5.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.5.cv3.0.m.1.cv2.conv.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.weight\n","freezing model.5.cv3.0.m.1.cv2.bn.bias\n","freezing model.5.cv3.1.conv.weight\n","freezing model.5.cv3.1.bn.weight\n","freezing model.5.cv3.1.bn.bias\n","freezing model.5.cv4.conv.weight\n","freezing model.5.cv4.bn.weight\n","freezing model.5.cv4.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.7.cv1.conv.weight\n","freezing model.7.cv1.bn.weight\n","freezing model.7.cv1.bn.bias\n","freezing model.7.cv2.0.cv1.conv.weight\n","freezing model.7.cv2.0.cv1.bn.weight\n","freezing model.7.cv2.0.cv1.bn.bias\n","freezing model.7.cv2.0.cv2.conv.weight\n","freezing model.7.cv2.0.cv2.bn.weight\n","freezing model.7.cv2.0.cv2.bn.bias\n","freezing model.7.cv2.0.cv3.conv.weight\n","freezing model.7.cv2.0.cv3.bn.weight\n","freezing model.7.cv2.0.cv3.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.0.cv2.conv.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.weight\n","freezing model.7.cv2.0.m.0.cv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv2.0.m.1.cv2.conv.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.weight\n","freezing model.7.cv2.0.m.1.cv2.bn.bias\n","freezing model.7.cv2.1.conv.weight\n","freezing model.7.cv2.1.bn.weight\n","freezing model.7.cv2.1.bn.bias\n","freezing model.7.cv3.0.cv1.conv.weight\n","freezing model.7.cv3.0.cv1.bn.weight\n","freezing model.7.cv3.0.cv1.bn.bias\n","freezing model.7.cv3.0.cv2.conv.weight\n","freezing model.7.cv3.0.cv2.bn.weight\n","freezing model.7.cv3.0.cv2.bn.bias\n","freezing model.7.cv3.0.cv3.conv.weight\n","freezing model.7.cv3.0.cv3.bn.weight\n","freezing model.7.cv3.0.cv3.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.0.cv2.conv.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.weight\n","freezing model.7.cv3.0.m.0.cv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.7.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.7.cv3.0.m.1.cv2.conv.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.weight\n","freezing model.7.cv3.0.m.1.cv2.bn.bias\n","freezing model.7.cv3.1.conv.weight\n","freezing model.7.cv3.1.bn.weight\n","freezing model.7.cv3.1.bn.bias\n","freezing model.7.cv4.conv.weight\n","freezing model.7.cv4.bn.weight\n","freezing model.7.cv4.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.0.cv1.conv.weight\n","freezing model.9.cv2.0.cv1.bn.weight\n","freezing model.9.cv2.0.cv1.bn.bias\n","freezing model.9.cv2.0.cv2.conv.weight\n","freezing model.9.cv2.0.cv2.bn.weight\n","freezing model.9.cv2.0.cv2.bn.bias\n","freezing model.9.cv2.0.cv3.conv.weight\n","freezing model.9.cv2.0.cv3.bn.weight\n","freezing model.9.cv2.0.cv3.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.0.cv2.conv.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.weight\n","freezing model.9.cv2.0.m.0.cv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv2.0.m.1.cv2.conv.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.weight\n","freezing model.9.cv2.0.m.1.cv2.bn.bias\n","freezing model.9.cv2.1.conv.weight\n","freezing model.9.cv2.1.bn.weight\n","freezing model.9.cv2.1.bn.bias\n","freezing model.9.cv3.0.cv1.conv.weight\n","freezing model.9.cv3.0.cv1.bn.weight\n","freezing model.9.cv3.0.cv1.bn.bias\n","freezing model.9.cv3.0.cv2.conv.weight\n","freezing model.9.cv3.0.cv2.bn.weight\n","freezing model.9.cv3.0.cv2.bn.bias\n","freezing model.9.cv3.0.cv3.conv.weight\n","freezing model.9.cv3.0.cv3.bn.weight\n","freezing model.9.cv3.0.cv3.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.0.cv2.conv.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.weight\n","freezing model.9.cv3.0.m.0.cv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.9.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.9.cv3.0.m.1.cv2.conv.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.weight\n","freezing model.9.cv3.0.m.1.cv2.bn.bias\n","freezing model.9.cv3.1.conv.weight\n","freezing model.9.cv3.1.bn.weight\n","freezing model.9.cv3.1.bn.bias\n","freezing model.9.cv4.conv.weight\n","freezing model.9.cv4.bn.weight\n","freezing model.9.cv4.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.conv.bias\n","freezing model.11.conv.weight\n","freezing model.11.conv.bias\n","freezing model.12.conv.weight\n","freezing model.12.conv.bias\n","freezing model.13.conv.weight\n","freezing model.13.conv.bias\n","freezing model.14.conv.weight\n","freezing model.14.conv.bias\n","freezing model.15.conv.weight\n","freezing model.15.bn.weight\n","freezing model.15.bn.bias\n","freezing model.17.conv.weight\n","freezing model.17.bn.weight\n","freezing model.17.bn.bias\n","freezing model.19.cv1.conv.weight\n","freezing model.19.cv1.bn.weight\n","freezing model.19.cv1.bn.bias\n","freezing model.19.cv2.0.cv1.conv.weight\n","freezing model.19.cv2.0.cv1.bn.weight\n","freezing model.19.cv2.0.cv1.bn.bias\n","freezing model.19.cv2.0.cv2.conv.weight\n","freezing model.19.cv2.0.cv2.bn.weight\n","freezing model.19.cv2.0.cv2.bn.bias\n","freezing model.19.cv2.0.cv3.conv.weight\n","freezing model.19.cv2.0.cv3.bn.weight\n","freezing model.19.cv2.0.cv3.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.0.cv2.conv.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.weight\n","freezing model.19.cv2.0.m.0.cv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv2.0.m.1.cv2.conv.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.weight\n","freezing model.19.cv2.0.m.1.cv2.bn.bias\n","freezing model.19.cv2.1.conv.weight\n","freezing model.19.cv2.1.bn.weight\n","freezing model.19.cv2.1.bn.bias\n","freezing model.19.cv3.0.cv1.conv.weight\n","freezing model.19.cv3.0.cv1.bn.weight\n","freezing model.19.cv3.0.cv1.bn.bias\n","freezing model.19.cv3.0.cv2.conv.weight\n","freezing model.19.cv3.0.cv2.bn.weight\n","freezing model.19.cv3.0.cv2.bn.bias\n","freezing model.19.cv3.0.cv3.conv.weight\n","freezing model.19.cv3.0.cv3.bn.weight\n","freezing model.19.cv3.0.cv3.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.0.cv2.conv.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.weight\n","freezing model.19.cv3.0.m.0.cv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.19.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.19.cv3.0.m.1.cv2.conv.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.weight\n","freezing model.19.cv3.0.m.1.cv2.bn.bias\n","freezing model.19.cv3.1.conv.weight\n","freezing model.19.cv3.1.bn.weight\n","freezing model.19.cv3.1.bn.bias\n","freezing model.19.cv4.conv.weight\n","freezing model.19.cv4.bn.weight\n","freezing model.19.cv4.bn.bias\n","freezing model.20.cv1.conv.weight\n","freezing model.20.cv1.bn.weight\n","freezing model.20.cv1.bn.bias\n","freezing model.20.cv2.conv.weight\n","freezing model.20.cv2.bn.weight\n","freezing model.20.cv2.bn.bias\n","freezing model.22.cv1.conv.weight\n","freezing model.22.cv1.bn.weight\n","freezing model.22.cv1.bn.bias\n","freezing model.22.cv2.0.cv1.conv.weight\n","freezing model.22.cv2.0.cv1.bn.weight\n","freezing model.22.cv2.0.cv1.bn.bias\n","freezing model.22.cv2.0.cv2.conv.weight\n","freezing model.22.cv2.0.cv2.bn.weight\n","freezing model.22.cv2.0.cv2.bn.bias\n","freezing model.22.cv2.0.cv3.conv.weight\n","freezing model.22.cv2.0.cv3.bn.weight\n","freezing model.22.cv2.0.cv3.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.0.cv2.conv.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.weight\n","freezing model.22.cv2.0.m.0.cv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv2.0.m.1.cv2.conv.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.weight\n","freezing model.22.cv2.0.m.1.cv2.bn.bias\n","freezing model.22.cv2.1.conv.weight\n","freezing model.22.cv2.1.bn.weight\n","freezing model.22.cv2.1.bn.bias\n","freezing model.22.cv3.0.cv1.conv.weight\n","freezing model.22.cv3.0.cv1.bn.weight\n","freezing model.22.cv3.0.cv1.bn.bias\n","freezing model.22.cv3.0.cv2.conv.weight\n","freezing model.22.cv3.0.cv2.bn.weight\n","freezing model.22.cv3.0.cv2.bn.bias\n","freezing model.22.cv3.0.cv3.conv.weight\n","freezing model.22.cv3.0.cv3.bn.weight\n","freezing model.22.cv3.0.cv3.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.0.cv2.conv.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.weight\n","freezing model.22.cv3.0.m.0.cv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.22.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.22.cv3.0.m.1.cv2.conv.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.weight\n","freezing model.22.cv3.0.m.1.cv2.bn.bias\n","freezing model.22.cv3.1.conv.weight\n","freezing model.22.cv3.1.bn.weight\n","freezing model.22.cv3.1.bn.bias\n","freezing model.22.cv4.conv.weight\n","freezing model.22.cv4.bn.weight\n","freezing model.22.cv4.bn.bias\n","freezing model.23.cv1.conv.weight\n","freezing model.23.cv1.bn.weight\n","freezing model.23.cv1.bn.bias\n","freezing model.23.cv2.conv.weight\n","freezing model.23.cv2.bn.weight\n","freezing model.23.cv2.bn.bias\n","freezing model.25.cv1.conv.weight\n","freezing model.25.cv1.bn.weight\n","freezing model.25.cv1.bn.bias\n","freezing model.25.cv2.0.cv1.conv.weight\n","freezing model.25.cv2.0.cv1.bn.weight\n","freezing model.25.cv2.0.cv1.bn.bias\n","freezing model.25.cv2.0.cv2.conv.weight\n","freezing model.25.cv2.0.cv2.bn.weight\n","freezing model.25.cv2.0.cv2.bn.bias\n","freezing model.25.cv2.0.cv3.conv.weight\n","freezing model.25.cv2.0.cv3.bn.weight\n","freezing model.25.cv2.0.cv3.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.0.cv2.conv.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.weight\n","freezing model.25.cv2.0.m.0.cv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv2.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv2.0.m.1.cv2.conv.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.weight\n","freezing model.25.cv2.0.m.1.cv2.bn.bias\n","freezing model.25.cv2.1.conv.weight\n","freezing model.25.cv2.1.bn.weight\n","freezing model.25.cv2.1.bn.bias\n","freezing model.25.cv3.0.cv1.conv.weight\n","freezing model.25.cv3.0.cv1.bn.weight\n","freezing model.25.cv3.0.cv1.bn.bias\n","freezing model.25.cv3.0.cv2.conv.weight\n","freezing model.25.cv3.0.cv2.bn.weight\n","freezing model.25.cv3.0.cv2.bn.bias\n","freezing model.25.cv3.0.cv3.conv.weight\n","freezing model.25.cv3.0.cv3.bn.weight\n","freezing model.25.cv3.0.cv3.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.0.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.0.cv2.conv.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.weight\n","freezing model.25.cv3.0.m.0.cv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv1.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv1.bn.bias\n","freezing model.25.cv3.0.m.1.cv1.conv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv1.conv2.bn.bias\n","freezing model.25.cv3.0.m.1.cv2.conv.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.weight\n","freezing model.25.cv3.0.m.1.cv2.bn.bias\n","freezing model.25.cv3.1.conv.weight\n","freezing model.25.cv3.1.bn.weight\n","freezing model.25.cv3.1.bn.bias\n","freezing model.25.cv4.conv.weight\n","freezing model.25.cv4.bn.weight\n","freezing model.25.cv4.bn.bias\n","freezing model.26.cv1.conv.weight\n","freezing model.26.cv1.bn.weight\n","freezing model.26.cv1.bn.bias\n","freezing model.26.cv2.conv.weight\n","freezing model.26.cv2.bn.weight\n","freezing model.26.cv2.bn.bias\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.00046875), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/Inconsistent/train.cache... 2636 images, 111 backgrounds, 0 corrupt: 100% 2636/2636 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/Inconsistent/val.cache... 1 images, 0 backgrounds, 0 corrupt: 100% 1/1 [00:00<?, ?it/s]\n","Plotting labels to /content/40e/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/40e/exp\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        0/9      6.02G      1.093     0.6451       1.36         19        640:   0% 0/264 [00:07<?, ?it/s]WARNING âš ï¸ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","        0/9      7.43G       1.09     0.6041      1.258         13        640: 100% 264/264 [04:46<00:00,  1.08s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/9      7.46G       1.07     0.6123      1.252         17        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/9      7.46G      1.058     0.6126      1.252         11        640: 100% 264/264 [04:34<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/9      7.46G      1.125     0.6613       1.26         11        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        4/9      7.46G      1.141     0.6768      1.275         12        640: 100% 264/264 [04:39<00:00,  1.06s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        5/9      7.46G       1.11     0.6601      1.272         16        640: 100% 264/264 [04:30<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        6/9      7.46G      1.099     0.6481      1.276         15        640: 100% 264/264 [04:32<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        7/9      7.46G      1.065     0.6261       1.26          8        640: 100% 264/264 [04:29<00:00,  1.02s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        8/9      7.46G      1.061     0.6113      1.255         17        640: 100% 264/264 [04:31<00:00,  1.03s/it]\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        9/9      7.46G       1.06     0.6025       1.26         11        640: 100% 264/264 [04:33<00:00,  1.04s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.15s/it]\n","                   all          1          1      0.972          1      0.995      0.796\n","\n","10 epochs completed in 0.780 hours.\n","Optimizer stripped from /content/40e/exp/weights/last.pt, 139.9MB\n","Optimizer stripped from /content/40e/exp/weights/best.pt, 139.9MB\n","\n","Validating /content/40e/exp/weights/best.pt...\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68547814 parameters, 0 gradients, 240.7 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.52it/s]\n","                   all          1          1      0.972          1      0.995      0.796\n","Results saved to \u001b[1m/content/40e/exp\u001b[0m\n"]}]},{"cell_type":"code","source":["results_saved_to = \"40e/exp\"\n","!zip -r {DRIVE}/40e.zip {HOME}/$results_saved_to"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6R8QuQJ4P6S","executionInfo":{"status":"ok","timestamp":1717107754856,"user_tz":-120,"elapsed":15230,"user":{"displayName":"Hallvard BjÃ¸rgen","userId":"14453308623544146932"}},"outputId":"9ad5ceff-057b-47be-9958-962c1bb71bf1"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/40e/exp/ (stored 0%)\n","  adding: content/40e/exp/confusion_matrix.png (deflated 43%)\n","  adding: content/40e/exp/train_batch1.jpg (deflated 25%)\n","  adding: content/40e/exp/labels_correlogram.jpg (deflated 41%)\n","  adding: content/40e/exp/R_curve.png (deflated 24%)\n","  adding: content/40e/exp/PR_curve.png (deflated 29%)\n","  adding: content/40e/exp/events.out.tfevents.1717104910.68b1c5c90573.145018.0 (deflated 20%)\n","  adding: content/40e/exp/weights/ (stored 0%)\n","  adding: content/40e/exp/weights/best.pt (deflated 8%)\n","  adding: content/40e/exp/weights/last.pt (deflated 8%)\n","  adding: content/40e/exp/val_batch0_pred.jpg (deflated 22%)\n","  adding: content/40e/exp/hyp.yaml (deflated 43%)\n","  adding: content/40e/exp/train_batch0.jpg (deflated 14%)\n","  adding: content/40e/exp/labels.jpg (deflated 33%)\n","  adding: content/40e/exp/P_curve.png (deflated 22%)\n","  adding: content/40e/exp/opt.yaml (deflated 50%)\n","  adding: content/40e/exp/results.csv (deflated 87%)\n","  adding: content/40e/exp/train_batch2.jpg (deflated 21%)\n","  adding: content/40e/exp/F1_curve.png (deflated 19%)\n","  adding: content/40e/exp/val_batch0_labels.jpg (deflated 22%)\n","  adding: content/40e/exp/results.png (deflated 13%)\n"]}]},{"cell_type":"markdown","source":["# FIMUS Consistent-2 training for Consistent-1 Evaluation, more epochs\n"],"metadata":{"id":"TUcRANMxUEwm"}},{"cell_type":"code","source":["!unzip -n -q {DRIVE}/FIMUSDataset/Consistent-2.zip -d {HOME}/dataset"],"metadata":{"id":"CNhKoeMSUKMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","\n","labels_path = '/content/dataset/Consistent-2/labels'\n","output_path = '/content/dataset/Consistent-2'\n","\n","# Ratios for splitting the datasets\n","train_ratio = 1\n","val_ratio = 0\n","\n","# test_ratio is implicitly determined\n","\n","# Get all file names without their extensions\n","filenames = [os.path.splitext(file)[0] for file in os.listdir(labels_path) if os.path.isfile(os.path.join(labels_path, file))]\n","\n","# Shuffle the list of filenames to ensure random distribution\n","random.shuffle(filenames)\n","\n","# Calculate split indices\n","no_total_files = len(filenames)\n","train_end = int(no_total_files * train_ratio)\n","print(train_end)\n","print(no_total_files)\n","\n","if(no_total_files == train_end):\n","  train_end-=1\n","\n","val_end = train_end + int(no_total_files * val_ratio) +1\n","\n","# Split the filenames\n","train_filenames = filenames[:train_end]\n","val_filenames = filenames[train_end:val_end]\n","test_filenames = filenames[val_end:]\n","print(val_filenames)\n","\n","# Function to write filenames to a file\n","def write_filenames_to_file(filenames, file_path):\n","    with open(file_path, 'w') as file:\n","        for name in filenames:\n","            file.write(f'./images/{name}.jpg\\n')\n","\n","# Write the splits to their respective files\n","write_filenames_to_file(train_filenames, os.path.join(output_path, 'train.txt'))\n","write_filenames_to_file(val_filenames, os.path.join(output_path, 'val.txt'))\n","write_filenames_to_file(test_filenames, os.path.join(output_path, 'test.txt'))\n","\n","print(\"Files have been split and saved successfully.\")"],"metadata":{"id":"8TZk4pcWU-q_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/FIMUSDataset/Consistent-2-20e.pt /content/weights/Consistent-2-20e.pt"],"metadata":{"id":"EoRYZZ2TVCnT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 30 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data-Consistent-2.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/Consistent-2-50e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/weights/Consistent-2-20e.pt \\\n","--freeze 28"],"metadata":{"id":"0z14VsvIdXPY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_saved_to = \"Consistent-2-50e/exp\"\n","!zip -r {DRIVE}/Consistent-2-50e.zip {HOME}/$results_saved_to"],"metadata":{"id":"_-R4bJ-hdYPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 25 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data-Consistent-2.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/Consistent-2-75e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/Consistent-2-50e/exp/weights/best.pt \\\n","--freeze 28"],"metadata":{"id":"KcBo085XdZO9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_saved_to = \"Consistent-2-75e/exp\"\n","!zip -r {DRIVE}/Consistent-2-75e.zip {HOME}/$results_saved_to"],"metadata":{"id":"hJmSVKcAdaRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 25 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data-Consistent-2.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/Consistent-2-100e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/Consistent-2-75e/exp/weights/best.pt \\\n","--freeze 28"],"metadata":{"id":"d7K7zhpVdbLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_saved_to = \"Consistent-2-100e/exp\"\n","!zip -r {DRIVE}/Consistent-2-100e.zip {HOME}/$results_saved_to"],"metadata":{"id":"YTQl3HJtdc8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 25 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data-Consistent-2.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/Consistent-2-125e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/Consistent-2-100e/exp/weights/best.pt \\\n","--freeze 28"],"metadata":{"id":"LY3Sd-j7deAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_saved_to = \"Consistent-2-125e/exp\"\n","!zip -r {DRIVE}/Consistent-2-125e.zip {HOME}/$results_saved_to"],"metadata":{"id":"x-YnlygWde5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!python yolov9-masterthesis/train_dual.py \\\n","--batch 10 \\\n","--epochs 25 \\\n","--img 640 \\\n","--min-items 0 \\\n","--data /content/yolov9-masterthesis/data-Consistent-2.yaml \\\n","--cfg yolov9-e.yaml \\\n","--project /content/Consistent-2-150e \\\n","--single-cls \\\n","--noval \\\n","--weights /content/Consistent-2-125e/exp/weights/best.pt \\\n","--freeze 28"],"metadata":{"id":"K-vft7wrdfxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_saved_to = \"Consistent-2-150e/exp\"\n","!zip -r {DRIVE}/Consistent-2-150e.zip {HOME}/$results_saved_to"],"metadata":{"id":"8lNbH5b8dgtc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SFGHb9k1YeLp"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1mOipVdy2WFMuxyF_A91Vc04jzxQDgI7E","timestamp":1717071130530}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}