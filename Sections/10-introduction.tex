\section{Introduction}
On-device processing is emerging as a vital component of modern human detection and tracking systems as an approach to ensure privacy. The ability to detect and track humans in real-time is crucial for a wide range of applications, from security surveillance to visitor analytics in cultural institutions. However, the deployment of such systems raises concerns about privacy and data security. Particularly in sensitive environments like museums and aquariums. This thesis details the development of a privacy-preserving human localization system. The developed system was then deployed and tested in a acquarium in Denmark.

The method of human detection and tracking in public spaces has evolved significantly over the past decade, driven by advancements in computer vision and machine learning. Traditional surveillance systems relied on centralized processing, where video feeds were transmitted to a remote server for manual human analysis. However, this approach raised privacy concerns as it involved transmitting raw video data over the network, potentially exposing sensitive information. Additionally, it also required a human to manually analyze the video feed, which was time-consuming, prone to errors, lacking of scalability, and not privacy-preserving. \textit{On-device} processing addresses this issue by performing analytics locally on the edge device, removing the need to transmit raw video data and thus enhancing privacy.

A device was deployed in the acquarium of "Fiskeri og SÃ¸fartsmuseet" in Esbjerg, Denmark. This was done to demonstrate the feasibility and effectiveness of on-device human detection and localization in a practical and realistic setting. Heatmaps were created from the data, and different filters applied to explore the need for such a system. The system faced challenges with regards to processing on-device and a dark-lit environment. The project in this thesis demonstrates how to overcome said challenges without the use of expensive night vision cameras. A Raspberry Pi 4 with a camera V2.1 module and a pre-trained YOLO object detection model version 9\footnote{YOLOv9 is not the current state of the art, but is used due to it's usability and familiarity. The SOTA Co-DETR, achieving better results than YOLOv9 on the COCO dataset, was attempted implemented but too great in size and not as easily fine-tuned as the YOLO series.} was used. The Raspberry pi no-ir camera module was also applied, but with little difference in results. The thesis used labeled images from the museum environment as training dataset, and evaluated the affects on model performance. The dataset for training, validation and testing is available on \href{https://drive.google.com/drive/folders/1_JXkpCqhaTc95XMjBc--Bkt0tH0Kdp-4?usp=sharing}{this Google Drive}.

\subsection{Scope}
The experiment was a hybrid between the sciences of edge-devices and machine learning, requiring knowledge and development in both ends. There were a lot of cross-diciplinary, time-consuming steps involved to produce the results (these steps are explained in section \ref{sec:methodology}).

Precautions had to be made in order to preserve individual privacy due to the experiment being a real-world live implementation. An already-developed system for secure communication with the raspberry pi's were borrowed from the \textit{HallMonitor}. This system set up a secure ssh tunnel to communicate with devices. Such a secure system of communication is necessary to ensure privacy when using devices able to capture images of unknowing individuals. The implementation of secure communication with edge devices is thus not included in this thesis.

Had the data been found online rather than independently collected, more time could have been spent exploring better ways of fine-tuning models. A larger number of machine learning models, including different variations of backbones and hyperparameters, could have been deployed to measure the differences in performance. This thesis includes the exploration of YOLOv3, YOLOv9, and DETR. The Co-DETR, the current best-performing model on the COCO dataset is also mentioned, but not implemented as it proved time-consuming to set up and slightly outside the scope of this project. 

The scope of this project and it's contribution to the field falls between showing a holistic implementation of how such a system may be developed and deployed, and the effects of certain choices during the development on the resulting outcome. For example, fine-tuning a YOLO model by freezing the backbone and fine-tuning the head for 5, 15 and 50 epochs showed a decline in performance of the model in this experimental layout. Altough a theoretically proven method of improving an object detection, this illustrates the need for good quality data in order for such an action to be helpful. Other explored variations were using a different dataset entirely to fine-tune the model, focusing more heavily on humans and from a more similar angle than that of the COCO dataset. 


\subsubsection{Research Questions}



\subsubsection{Research Objectives}

\subsection{Structure}


